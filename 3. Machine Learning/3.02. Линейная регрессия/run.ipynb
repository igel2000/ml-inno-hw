{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузить датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/competitions/playground-series-s3e11/data\n",
    "dataset_df = pd.read_csv('dataset/train.csv', index_col=\"id\")\n",
    "dataset_df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание свойств:\n",
    "* store_sales(in millions) — продажи в магазине (в миллионах долларов)\n",
    "* unit_sales(in millions) — продажи в магазине (в миллионах) Количество\n",
    "* total_children — ВСЕ ДЕТИ В ДОМЕ\n",
    "* num_children_at_home — количество детей в доме согласно заполненным клиентами данным\n",
    "* avg_cars_at home(approx).1 — среднее количество автомобилей в доме (приблизительно)\n",
    "* gross_weight — вес брутто\n",
    "* recyclable_package — ПИЩЕВОЙ ПРОДУКТ В ПЕРЕРАБАТЫВАЕМОЙ_УПАКОВКЕ\n",
    "* low_fat — ПИЩЕВОЙ ПРОДУКТ С НИЗКИМ СОДЕРЖАНИЕМ ЖИРА\n",
    "* units_per_case — ЕДИНИЦ/ЯЩИК, ДОСТУПНЫХ НА КАЖДОЙ ПОЛКЕ В МАГАЗИНЕ\n",
    "* store_sqft — ПЛОЩАДЬ МАГАЗИНА, ДОСТУПНАЯ В КВАДРАТНЫХ ФУТАХ\n",
    "* coffee_bar — КОФЕЙНЫЙ БАР, доступный в магазине\n",
    "* video_store — ВИДЕОМАГАЗИН/игровой магазин, доступный в магазине\n",
    "* salad_bar — САЛАТНЫЙ БАР, доступный в магазине\n",
    "* prepared_food — ПРИГОТОВЛЕННАЯ ЕДА, доступная в магазине\n",
    "* florist — цветочные полки, доступные в магазине\n",
    "* cost — затраты на привлечение клиентов в долларах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_df(df):\n",
    "    \"\"\"Провести EDA для датафрейма\"\"\"\n",
    "    df_describe = df.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "    # посчитать долю пропусков\n",
    "    df_describe.loc[\"%nan\"] = (df.isna().mean()*100).to_list()\n",
    "    # посчитать дисперсию\n",
    "    columns_var = []\n",
    "    for column in df_describe.columns:\n",
    "        columns_var.append(df[column].var())\n",
    "    df_describe.loc['var'] = columns_var\n",
    "    return df_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_describe = eda_df(dataset_df)\n",
    "dataset_df_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = []\n",
    "categorical = []\n",
    "for col in dataset_df.columns:\n",
    "    if dataset_df[col].nunique() <= 2:\n",
    "        categorical.append(col)\n",
    "    else:\n",
    "        numerical.append(col)\n",
    "pprint(f'categorical={categorical}')\n",
    "pprint(f'numerical={numerical}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы по набору данных:\n",
    "  * все переменные числовые\n",
    "  * пропусков нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_boxes(df, columns, ncols = 3):\n",
    "    \"\"\"Показать 'ящики_с_усами' для набора df.\n",
    "    Ящики будут показаны для столбцов датафрема, перечисленных в columns.\n",
    "    Графики будут показаны в несколько столбцов, количество которых задается в параметре ncols.\"\"\"\n",
    "    nrows = int(round((len(columns) + 0.5) / ncols, 0))\n",
    "    nrows = nrows if nrows > 1 else 1\n",
    "\n",
    "    fig = make_subplots(rows=nrows, cols=ncols)\n",
    "    fig.update_layout(\n",
    "        title_x=0.5,\n",
    "        title_text=\"Ящики с усами\",\n",
    "        height=500*nrows, \n",
    "        width=800\n",
    "    )\n",
    "    i = 0\n",
    "    for r in range(nrows):\n",
    "        for c in range(ncols):\n",
    "            fig.add_box(y=df[columns[i]], name=columns[i], row=r+1, col=c+1)\n",
    "            i += 1\n",
    "            if i >= len(columns):\n",
    "                break\n",
    "        if i >= len(columns):\n",
    "            break\n",
    "    fig.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.а. Анализ целевой переменной cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    title_text=\"Анализ целевой переменной cost\",\n",
    "    height=500, \n",
    "    width=1200\n",
    ")\n",
    "fig.add_box(y=dataset_df[\"cost\"], name=\"cost\", row=1, col=1)\n",
    "fig.add_histogram(x=dataset_df[\"cost\"], name=\"cost\", row=1, col=2)\n",
    "fig.show()   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение целевой переменной - равномерное.\n",
    "Выбросов нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b. Обработка пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = msno.matrix(dataset_df, figsize=(12,2), fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.c. Обработка выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dataset_df.columns.to_list()\n",
    "columns.remove(\"cost\")\n",
    "show_boxes(dataset_df, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбросы есть в полях: `store_sales(in millions)`, `unit_sales(in millions)`, `num_children_at_home`. \n",
    "Но `unit_sales(in millions)`, `num_children_at_home` это скорее ранговые переменные.  Проверим их распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    title_text=\"Распределение значений свойств\",\n",
    "    height=500, \n",
    "    width=1200\n",
    ")\n",
    "fig.add_histogram(x=dataset_df[\"unit_sales(in millions)\"], name=\"unit_sales(in millions)\", row=1, col=1)\n",
    "fig.add_histogram(x=dataset_df[\"num_children_at_home\"], name=\"num_children_at_home\", row=1, col=2)\n",
    "fig.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У `unit_sales(in millions)` - нормальное распределение, у `num_children_at_home` - экспоненциальное.\n",
    "\n",
    "Предполагаю, что выбросы специально обрабатывать не надо у этих свойств.\n",
    "\n",
    "Уберем выбросы у `store_sales(in millions)`. Т.к. выбросы все \"сверху\", то заменим их максимальные значения внутри IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'store_sales(in millions)'\n",
    "Q3 = np.quantile(dataset_df[column], 0.75, axis=0)\n",
    "Q1 = np.quantile(dataset_df[column], 0.25, axis=0)\n",
    "IQR = Q3 - Q1\n",
    "upper = Q3 + 1.5 * IQR\n",
    "lower = Q1 - 1.5 * IQR\n",
    "dataset_df.loc[dataset_df[column] > upper]\n",
    "# добавим столбец, в котором избавимся от выбросов в 'store_sales(in millions)', заменив их максимальными или минимальными значениями\n",
    "dataset_df[f'{column}_without_outliers'] = dataset_df[column].map(lambda x: lower if x<lower else x if x<=upper else upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверить, что в новом столбце нет выбросов\n",
    "show_boxes(dataset_df, ['store_sales(in millions)', 'store_sales(in millions)_without_outliers'], ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.d. Анализ корреляцие между столбцами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(dataset_df.corr(method='spearman'), height=1000, width=1000, text_auto='.2f')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Высоковата корреляция между столбцами:\n",
    "  * florist + coffer_bar\n",
    "  * florist + video_store\n",
    "  * florist + salad_bar\n",
    "  * florist + prepared_food\n",
    "  * prepared_food + video_store\n",
    "  * salad_bar + video_store\n",
    "  * salad_bar + prepared_food\n",
    "  * video_store + coffer_bar\n",
    "  * store_sales(in millions) + unit_sales(in millions)\n",
    "  * total_children и num_children_at_home.\n",
    "\n",
    "Попробуем исключить из модели florist, video_store, salad_bar, store_sales(in millions) и total_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_for_remove = ['florist', 'video_store', 'unit_sales(in millions)']\n",
    "columns_without_corr = dataset_df.columns.to_list()\n",
    "for col in columns_for_remove:\n",
    "    columns_without_corr.remove(col)\n",
    "fig = px.imshow(dataset_df[columns_without_corr].corr(method='spearman'), height=1000, width=1000, text_auto='.2f')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.e. Разделить на набор данных на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделить набор данных на тренировочную и тестовую выборки\n",
    "columns = dataset_df.columns.to_list()\n",
    "# убрать целевую переменную\n",
    "columns.remove(\"cost\")\n",
    "# убать оригинальный столбек с выбросами\n",
    "columns.remove('store_sales(in millions)')\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_df[columns], \n",
    "                                                    dataset_df['cost'],\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "print(f'X_train.shape={X_train.shape},  X_test.shape={X_test.shape}')\n",
    "print(f'y_train.mean()={y_train.mean()}, y_test.mean()={y_test.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделить набор данных на тренировочную и тестовую выборки (без столбцов с корреляцией)\n",
    "columns = copy.deepcopy(columns_without_corr)\n",
    "# убрать целевую переменную\n",
    "columns.remove(\"cost\")\n",
    "# убать оригинальный столбек с выбросами\n",
    "columns.remove('store_sales(in millions)')\n",
    "X_train_wo_corr, X_test_wo_corr, y_train_wo_corr, y_test_wo_corr = train_test_split(dataset_df[columns], \n",
    "                                                                                    dataset_df['cost'],\n",
    "                                                                                    test_size=0.2, random_state=42)\n",
    "print(f'X_train_wo_corr.shape={X_train_wo_corr.shape},  X_test.shape={X_test_wo_corr.shape}')\n",
    "print(f'y_train_wo_corr.mean()={y_train_wo_corr.mean()}, y_test.mean()={y_test_wo_corr.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Оценить качество модели\"\"\"\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)    \n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    rmse_test = root_mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)    \n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    rmse_train = root_mean_squared_error(y_train, y_train_pred)\n",
    "    \n",
    "    print('Train data:')\n",
    "    print(f\"  MSE:    {round(mse_train,4)}\")\n",
    "    print(f\"  RMSE:   {round(rmse_train,4)}\")\n",
    "    print(f\"  MAE:    {round(mae_train,4)}\")\n",
    "    print(f\"  r2:     {round(r2_train,4)}\")\n",
    "    print(f\"  median: {round(y_train.median(),4)}\")\n",
    "\n",
    "    print('Test data:')\n",
    "    print(f\"  MSE:    {round(mse_test,4)}\")\n",
    "    print(f\"  RMSE:   {round(rmse_test,4)}\")\n",
    "    print(f\"  MAE:    {round(mae_test,4)}\")\n",
    "    print(f\"  r2:     {round(r2_test,4)}\")    \n",
    "    print(f\"  median: {round(y_test.median(),4)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.a. statsmodel.OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_OLS_model(X_train, y_train, X_test, y_test, columns):\n",
    "    X_train_OLS = copy.deepcopy(X_train[columns])\n",
    "    X_test_OLS = copy.deepcopy(X_test[columns])\n",
    "    y_train_OLS = copy.deepcopy(y_train)\n",
    "    y_test_OLS = copy.deepcopy(y_test)    \n",
    "\n",
    "    X_train_OLS = sm.add_constant(X_train_OLS, prepend=False)\n",
    "    X_test_OLS = sm.add_constant(X_test_OLS, prepend=False)\n",
    "    model_OLS = OLS(y_train_OLS, X_train_OLS)\n",
    "    res_OLS = model_OLS.fit()\n",
    "    return model_OLS, res_OLS, X_train_OLS, X_test_OLS, y_train_OLS, y_test_OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a.i OLS-модель с оригинальными столбцами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построить модель по всем столбцам\n",
    "columns = X_train.columns.to_list()\n",
    "model_OLS, res_OLS, X_train_OLS, X_test_OLS, y_train_OLS, y_test_OLS = build_OLS_model(X_train, y_train, X_test, y_test, columns)\n",
    "# оценим модель\n",
    "print(res_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(res_OLS, X_train_OLS, y_train_OLS, X_test_OLS, y_test_OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value высокое у num_children_at_home, gross_weight, recyclable_package, low_fat, units_per_case и store_sales(in millions)_without_outliers \n",
    "\n",
    "Надо попробовать исключить их их модели и снова построить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns.to_list()\n",
    "columns.remove('num_children_at_home')\n",
    "columns.remove('gross_weight')\n",
    "columns.remove('recyclable_package')\n",
    "columns.remove('low_fat')\n",
    "columns.remove('units_per_case')\n",
    "columns.remove('store_sales(in millions)_without_outliers')\n",
    "model_OLS2, res_OLS2, X_train_OLS2, X_test_OLS2, y_train_OLS2, y_test_OLS2 = build_OLS_model(X_train, y_train, X_test, y_test, columns)\n",
    "# оценим модель\n",
    "print(res_OLS2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared не изменилось после удаления столбцов - значи их можно безопасно удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(res_OLS2, X_train_OLS2, y_train_OLS2, X_test_OLS2, y_test_OLS2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a.ii OLS-модель с столбцами без корреляций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построить модель по всем столбцам\n",
    "columns = X_train_wo_corr.columns.to_list()\n",
    "model_OLS_wo_corr, res_OLS_wo_corr, X_train_OLS_wo_corr, X_test_OLS_wo_corr, y_train_OLS_wo_corr, y_test_OLS_wo_corr = build_OLS_model(X_train_wo_corr, y_train_wo_corr, X_test_wo_corr, y_test_wo_corr, columns)\n",
    "# оценим модель\n",
    "print(res_OLS_wo_corr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(res_OLS_wo_corr, X_train_OLS_wo_corr, y_train_OLS_wo_corr, X_test_OLS_wo_corr, y_test_OLS_wo_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train_wo_corr.columns.to_list()\n",
    "columns.remove('num_children_at_home')\n",
    "columns.remove('gross_weight')\n",
    "columns.remove('recyclable_package')\n",
    "columns.remove('low_fat')\n",
    "columns.remove('units_per_case')\n",
    "columns.remove('salad_bar')\n",
    "model_OLS2_wo_corr, res_OLS2_wo_corr, X_train_OLS2_wo_corr, X_test_OLS2_wo_corr, y_train_OLS2_wo_corr, y_test_OLS2_wo_corr = build_OLS_model(X_train_wo_corr, y_train_wo_corr, X_test_wo_corr, y_test_wo_corr, columns)\n",
    "# оценим модель\n",
    "print(res_OLS2_wo_corr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(res_OLS2_wo_corr, X_train_OLS2_wo_corr, y_train_OLS2_wo_corr, X_test_OLS2_wo_corr, y_test_OLS2_wo_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.b. scikit-learn.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LR_model(X_train, y_train, X_test, y_test, columns):\n",
    "    \"\"\"Построить LinearRegression-модель\"\"\"\n",
    "    X_train_LR = copy.deepcopy(X_train[columns])\n",
    "    X_test_LR = copy.deepcopy(X_test[columns])\n",
    "    y_train_LR = copy.deepcopy(y_train)\n",
    "    y_test_LR = copy.deepcopy(y_test)    \n",
    "\n",
    "    model_LR = LinearRegression()\n",
    "    res_LR = model_LR.fit(X_train_LR, y_train_LR)\n",
    "    return model_LR, res_LR, X_train_LR, X_test_LR, y_train_LR, y_test_LR\n",
    "\n",
    "def show_LR_coef(model_LR):\n",
    "    print('Коэффициенты модели:')\n",
    "    for i in range(len(model_LR.feature_names_in_)):\n",
    "        print(f'  {model_LR.feature_names_in_[i]}={round(model_LR.coef_[i],4)}')\n",
    "    print(f'  const={round(model_LR.intercept_, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b.i LR-модель с оригинальными столбцами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = X_train.columns.to_list()\n",
    "model_LR, res_LR, X_train_LR, X_test_LR, y_train_LR, y_test_LR = build_LR_model(X_train, y_train, X_test, y_test, columns)\n",
    "check_model(res_LR, X_train_LR, y_train, X_test_LR, y_test_LR)\n",
    "show_LR_coef(res_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b.ii LR-модель со столбцами без корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train_wo_corr.columns.to_list()\n",
    "model_LR_wo_corr, res_LR_wo_corr, X_train_LR_wo_corr, X_test_LR_wo_corr, y_train_LR_wo_corr, y_test_LR_wo_corr = build_LR_model(X_train_wo_corr, y_train_wo_corr, X_test_wo_corr, y_test_wo_corr, columns)\n",
    "check_model(res_LR_wo_corr, X_train_LR_wo_corr, y_train_wo_corr, X_test_LR_wo_corr, y_test_LR_wo_corr)\n",
    "show_LR_coef(res_LR_wo_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "Оба типа моделей (OLS и LR) показывают сопоставимые результаты.\n",
    "Удаление стоблцов с корреляцией как минимум не улучшает (а скорее - ухудшает) качество модели - метрики MSE, RMSE, MAE остаются практически теми же, при этом метрика R-squared ухудшается.\n",
    "\n",
    "В целом, получившиеся модели малополезны дял предсказания, т.к.: \n",
    "* RMSE сопоставимо с медианным значением целевой переменной\n",
    "* R-squared мало - 0.02 в лучшем случае.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

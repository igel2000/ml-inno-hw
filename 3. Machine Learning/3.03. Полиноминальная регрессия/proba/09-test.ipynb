{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия, полиноминальная, Lasso, Ridge и ElasticNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "from pprint import pprint, pformat\n",
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "\n",
    "from my_lib import *\n",
    "from my_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # для построения моделей линейной регрессии\n",
    "from sklearn.preprocessing import PolynomialFeatures # для преобразования исходных признаков в полиномиальные, для построения моделей полиномиальной регрессии\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer, PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_df = joblib.load(Path(result_foler, dataset_filename_after_PrepareTarget))\n",
    "params = joblib.load(Path(result_foler, params_filename_after_PrepareTarget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_df_X  = dataset_df.drop([params[\"target_column\"]], axis=1)\n",
    "#dataset_df_Y  = dataset_df[params[\"target_column\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_name = 'NoScaler'\n",
    "X_train =joblib.load(Path(result_foler, X_train_template_filename_after_split % scaler_name))\n",
    "X_test = joblib.load(Path(result_foler, X_test_template_filename_after_split % scaler_name))\n",
    "y_train =joblib.load(Path(result_foler, y_train_template_filename_after_split % scaler_name))\n",
    "y_test = joblib.load(Path(result_foler, y_test_template_filename_after_split % scaler_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабирование\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(dataset_df_X)\n",
    "\n",
    "# Добавление полиномиальных признаков\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "\n",
    "# Обучение модели\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "print(f'R² score: {r2_score(y_test, y_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores = pd.DataFrame(columns=[\"r2_score_train\", \"r2_score_test\",\n",
    "                                      \"mse_train\", \"mse_test\", \n",
    "                                      \"rmse_train\", \"rmse_test\", \n",
    "                                      \"mae_train\", \"mae_test\",\n",
    "                                      \"coef\", \"params\"\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем интервал перебора для alpha\n",
    "# альфа зависит от размера выборки\n",
    "\n",
    "start = 10      # Начальное значение диапазона\n",
    "stop = 1000       # Конечное значение диапазона (не включается в результат)\n",
    "step = 10       # Шаг между значениями\n",
    "float_range = np.arange(start, stop, step)\n",
    "print(float_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавить масшабирование признаков и целевых переменных\n",
    "scalers = {'NoScaler': None,\n",
    "           'StandardScaler': StandardScaler(),\n",
    "           'MinMaxScaler': MinMaxScaler(),\n",
    "           'MaxAbsScaler': MaxAbsScaler(),\n",
    "           'RobustScaler': RobustScaler()\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scalers = ['NoScaler', 'StandardScaler', 'MinMaxScaler', 'MaxAbsScaler', 'RobustScaler']\n",
    "#scalers = ['StandardScaler']\n",
    "#scalers = ['MinMaxScaler']\n",
    "#scalers = ['MaxAbsScaler']\n",
    "#scalers = ['RobustScaler']\n",
    "#scalers = ['NoScaler']\n",
    "for scaler_name in scalers:\n",
    "    X_train =joblib.load(Path(result_foler, X_train_template_filename_after_split % scaler_name))\n",
    "    X_test = joblib.load(Path(result_foler, X_test_template_filename_after_split % scaler_name))\n",
    "    y_train =joblib.load(Path(result_foler, y_train_template_filename_after_split % scaler_name))\n",
    "    y_test = joblib.load(Path(result_foler, y_test_template_filename_after_split % scaler_name))\n",
    "\n",
    "    # -------------------- LinearRegression() --------------------\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg_fit = lin_reg.fit(X_train, y_train)\n",
    "    Y_pred_train_lin = lin_reg_fit.predict(X_train) # train\n",
    "    Y_pred_test_lin = lin_reg_fit.predict(X_test) # test\n",
    "    add_scores(models_scores, f\"{scaler_name}_LinearRegression\", \n",
    "               y_train, Y_pred_train_lin, y_test, Y_pred_test_lin, \n",
    "               pformat(lin_reg_fit.get_params()), f\"{lin_reg_fit.coef_}, const={lin_reg_fit.intercept_}\")\n",
    "    #display(models_scores)\n",
    "\n",
    "    # -------------------- PolynomialFeatures() --------------------\n",
    "    for d in [2, 3]:\n",
    "        poly_features = PolynomialFeatures(degree=d) # степень до 7, долго\n",
    "        X_train_poly = poly_features.fit_transform(X_train)\n",
    "        X_test_poly = poly_features.transform(X_test)\n",
    "        poly_reg = LinearRegression()\n",
    "        poly_reg_fit = poly_reg.fit(X_train_poly, y_train)    \n",
    "        \n",
    "        Y_pred_train_poly = poly_reg_fit.predict(X_train_poly)\n",
    "        Y_pred_test_poly = poly_reg_fit.predict(X_test_poly)    \n",
    "\n",
    "        add_scores(models_scores, f\"{scaler_name}_PolynomialFeatures(degree={d})\", \n",
    "                   y_train, Y_pred_train_poly, y_test, Y_pred_test_poly, \n",
    "                   pformat(poly_reg_fit.get_params()), f\"{poly_reg_fit.coef_}, const={poly_reg_fit.intercept_}\")\n",
    "        #display(models_scores)\n",
    "        \n",
    "\n",
    "    # -------------------- ElasticNet() --------------------\n",
    "    param_grid = {\n",
    "        'alpha': [0.00005, 0.0005, 0.001, 0.01, 0.05, 0.06, 0.08, 1, 2, 3],\n",
    "        'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    }\n",
    "    elastic_net = GridSearchCV(ElasticNet(), param_grid, scoring='r2', cv=10)        \n",
    "    res_elastic_net_model = elastic_net.fit(X_train, y_train)\n",
    "\n",
    "    # построим регрессию гребневую L2 с оптимальным параметром регуляризации, который мы подобрали перебором\n",
    "    model_reg_elastic = ElasticNet(max_iter=1000, **res_elastic_net_model.best_params_) # alpha — величина регуляризации\n",
    "\n",
    "    # обучение\n",
    "    model_reg_elastic.fit(X_train, y_train)\n",
    "    y_pred_test_elastic = model_reg_elastic.predict(X_test)\n",
    "    y_pred_train_elastic = model_reg_elastic.predict(X_train)\n",
    "\n",
    "    add_scores(models_scores, f\"{scaler_name}_ElasticNet\", \n",
    "               y_train, y_pred_train_elastic, y_test, y_pred_test_elastic, \n",
    "               pformat(res_elastic_net_model.best_params_), f\"{model_reg_elastic.coef_}, const={model_reg_elastic.intercept_}\")\n",
    "    #display(models_scores)\n",
    "    \n",
    "    # -------------------- Ridge() --------------------\n",
    "    param_grid = {\n",
    "        'alpha': float_range\n",
    "    }\n",
    "\n",
    "    ridge = GridSearchCV(Ridge(), param_grid, scoring='r2', cv=10)        \n",
    "    res_ridge_model = ridge.fit(X_train, y_train)\n",
    "\n",
    "    # построим регрессию гребневую L2 с оптимальным параметром регуляризации, который мы подобрали перебором\n",
    "    model_ridge = Ridge(max_iter=1000, **res_ridge_model.best_params_) # alpha — величина регуляризации\n",
    "\n",
    "    # обучение\n",
    "    model_ridge.fit(X_train, y_train)\n",
    "    y_pred_test_elastic = model_ridge.predict(X_test)\n",
    "    y_pred_train_elastic = model_ridge.predict(X_train)\n",
    "\n",
    "    add_scores(models_scores, f\"{scaler_name}_Ridge\", \n",
    "               y_train, y_pred_train_elastic, y_test, y_pred_test_elastic, \n",
    "               pformat(res_ridge_model.best_params_), f\"{model_ridge.coef_}, const={model_ridge.intercept_}\")\n",
    "    #display(models_scores)    \n",
    "    \n",
    "    # -------------------- Lasso() --------------------\n",
    "    param_grid = {\n",
    "        'alpha': float_range\n",
    "    }\n",
    "\n",
    "    lasso = GridSearchCV(Lasso(), param_grid, scoring='r2', cv=10)        \n",
    "    res_lasso_model = lasso.fit(X_train, y_train)\n",
    "\n",
    "    # построим регрессию гребневую L2 с оптимальным параметром регуляризации, который мы подобрали перебором\n",
    "    model_lasso = Lasso(max_iter=1000, **res_lasso_model.best_params_) # alpha — величина регуляризации\n",
    "\n",
    "    # обучение\n",
    "    model_lasso.fit(X_train, y_train)\n",
    "    y_pred_test_elastic = model_lasso.predict(X_test)\n",
    "    y_pred_train_elastic = model_lasso.predict(X_train)\n",
    "\n",
    "    add_scores(models_scores, f\"{scaler_name}_Lasso\", \n",
    "               y_train, y_pred_train_elastic, y_test, y_pred_test_elastic, \n",
    "               pformat(res_lasso_model.best_params_), f\"{model_lasso.coef_}, const={model_lasso.intercept_}\")\n",
    "\n",
    "    display(models_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(models_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Коэффициенты моделей:\")\n",
    "for i in models_scores.index:\n",
    "    print(f'{i}: {models_scores.loc[i][\"coef\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Гиперпараметры моделей:\")\n",
    "for i in models_scores.index:\n",
    "    print(f'{i}: {models_scores.loc[i][\"params\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"r2_score моделей:\")\n",
    "for i in models_scores.index:\n",
    "    print(f'{i:45}| train: {round(models_scores.loc[i][\"r2_score_train\"],8):10}  | test: {round(models_scores.loc[i][\"r2_score_test\"],8):10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате были построены модели:\n",
    "  * линейная регрессия\n",
    "  * полиноминальная регрессия с degree=2, 3\n",
    "  * ElasticNet с подбором гиперпараметров\n",
    "  * Ridge с подбором гиперпараметров\n",
    "  * Lasso с подбором гиперпараметров\n",
    "\n",
    "для нескольких наборов данных, отличающихся примененным алгоритмом нормализации данных - без нормализации, 'StandardScaler', 'MinMaxScaler', 'MaxAbsScaler', 'RobustScaler'.\n",
    "\n",
    "Также проверялись разные подходы к подготовке набора данных:\n",
    "  * с удалением столбцов с большой долей пропусков\n",
    "  * с заполнением пропусков модой и с удалением строк, в которых есть пропуски\n",
    "  * разные настройки OneHotEncoder\n",
    "\n",
    "\n",
    "Результат был примерно один и тот же. В частности метрика r2_score колебалась в диапазоне от 0.0016 до 0.0040, что крайне мало и показывает, что построенные модели непригодны для прогнозирования целевой функции.\n",
    "Следовательно:\n",
    "* либо методы регрессии не подходят к решению этой задаче\n",
    "* либо где-то ошибка в коде\n",
    "* либо в принципе неверный подход к подготовке данных и/или обучению моделей\n",
    "* либо неверно интерпретирую метрики\n",
    "\n",
    "Предполагаю, что какая-то из двух последних причин. Нужна обратная связь.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

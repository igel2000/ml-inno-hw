{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Импорты и библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from pathlib import Path\n",
    "from pprint import pprint, pformat\n",
    "import zipfile\n",
    "\n",
    "import opendatasets as od \n",
    "import pandas as pd\n",
    "import pandas.api.types as pd_types\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as plotly_px\n",
    "import plotly.graph_objects as plotly_go\n",
    "import plotly.subplots as plotly_subplt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import builtins\n",
    "from pathlib import Path\n",
    "import time\n",
    "import tqdm\n",
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    train_test_split,  # Функция для разделения данных на обучающую и тестовую выборки\n",
    "    cross_val_score, # оценщик кросс-валидации\n",
    "    GridSearchCV,  # Класс для поиска гиперпараметров с помощью сеточного поиска\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (OneHotEncoder, \n",
    "                                   OrdinalEncoder\n",
    "                                  )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотека"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaseLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLib():\n",
    "    @staticmethod\n",
    "    def st():\n",
    "        \"\"\"старт таймера\"\"\"\n",
    "        return time.monotonic_ns()\n",
    "    @staticmethod\n",
    "    def ft(start):\n",
    "        \"\"\"финиш таймера и вывод времени\"\"\"\n",
    "        duration = (time.monotonic_ns() - start) / 1000000000\n",
    "        print(f'Затрачено времени: {duration:.2f} секунд')\n",
    "        return duration\n",
    "\n",
    "    @staticmethod\n",
    "    def get_type(type_name):\n",
    "        try:\n",
    "            return getattr(builtins, type_name)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                obj = globals()[type_name]\n",
    "            except KeyError:\n",
    "                return None\n",
    "            return repr(obj) if isinstance(obj, type) else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSetLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetLib():\n",
    "    \"\"\"Библиотека функций для работы с датасетом\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def columns_by_type(df, target_name, cat_treshold=2):\n",
    "        \"\"\"Сфромировать словарь, с разделением имен столбцов по типам:\n",
    "        - target_columns - целевой столбец\n",
    "        - columns_X - все столбцы-фичи\n",
    "        - num_columns - числовые столбцы\n",
    "        - cat_columns - категориальные. Категориальными считаютс и числовые столбцы, в которых уникальных значений меньше или равно  cat_treshold\"\"\"\n",
    "        params = {}\n",
    "        # columns_X - переменные датасета\n",
    "        params[\"columns_X\"] = df.columns.to_list()\n",
    "        # целевой столбец\n",
    "        params[\"target_column\"] = target_name\n",
    "        if target_name is not None:\n",
    "            params[\"columns_X\"].remove(params[\"target_column\"])\n",
    "        params[\"num_columns\"] = []\n",
    "        params[\"cat_columns\"] = []\n",
    "        # определить числовые и категориальные столбцы\n",
    "        for col in params[\"columns_X\"]:\n",
    "            if df[col].nunique() <= cat_treshold or not pd_types.is_numeric_dtype(df[col]):\n",
    "                params[\"cat_columns\"].append(col)\n",
    "            else:\n",
    "                params[\"num_columns\"].append(col)\n",
    "        #print(f'target_columns={params[\"target_column\"]}')        \n",
    "        #print(f'columns_X={params[\"columns_X\"]}')\n",
    "        #print(f'cat_columns={pformat(params[\"cat_columns\"])}')\n",
    "        #print(f'num_columns={pformat(params[\"num_columns\"])}')\n",
    "        return params\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_columns(params, column): \n",
    "        \"\"\"удалить столбец и словаря параметров\"\"\"\n",
    "        if column in params[\"columns_X\"]:\n",
    "            params[\"columns_X\"].remove(column)\n",
    "        if column in params[\"num_columns\"]:\n",
    "            params[\"num_columns\"].remove(column)\n",
    "        if column in params[\"cat_columns\"]:\n",
    "            params[\"cat_columns\"].remove(column)\n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def add_columns(params, column, type_column): \n",
    "        \"\"\"добавить столбец в словарь параметров\n",
    "        type_column = \"cat\" или \"num\" или None \"\"\"\n",
    "        if column not in params[\"columns_X\"]:\n",
    "            params[\"columns_X\"].append(column)\n",
    "        if type_column is None:\n",
    "            pass\n",
    "        elif type_column == \"cat\":\n",
    "            params[\"cat_columns\"].append(column)\n",
    "        elif type_column == \"num\":\n",
    "            params[\"num_columns\"].append(column)\n",
    "        else:\n",
    "            raise ValueError(\"type_column должен быть 'cat' или 'num'\")\n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def describe_columns(df, params):\n",
    "        \"\"\"Отобразить описание содержимого столбцов\"\"\"    \n",
    "        # подсчет столбцов с пропусками\n",
    "        nan_in_columns = DataSetLib.nans_percents(df)\n",
    "        \n",
    "        print(\"Количество уникальных значений по столбцам, доля пропусков и уникальные значения, если их не более 10\")\n",
    "        nunique = df[params[\"columns_X\"]].nunique()\n",
    "        for column in nunique.index:\n",
    "            if column in params[\"cat_columns\"]:\n",
    "                column_type = \"[c]\" # категориальные\n",
    "            else:\n",
    "                column_type = \"[n]\" # числовые\n",
    "                \n",
    "            if nan_in_columns[column] > 0:\n",
    "                nan_str = f'({nan_in_columns[column]:4.1f}%)'\n",
    "            else:\n",
    "                nan_str = \" \"*7\n",
    "            if nunique[column] <= 10:\n",
    "                print(f'{column:20}{column_type}: {nunique[column]:6} {nan_str}, {df[column].unique().tolist()}')\n",
    "            else:\n",
    "                print(f'{column:20}{column_type}: {nunique[column]:6} {nan_str}')\n",
    "\n",
    "        if params[\"target_column\"] is not None:\n",
    "            df_describe_num = DataSetLib.eda_df(df[params[\"num_columns\"]+[params[\"target_column\"]]])\n",
    "        else:\n",
    "            df_describe_num = DataSetLib.eda_df(df[params[\"num_columns\"]])\n",
    "        display(df_describe_num)            \n",
    "\n",
    "        df_describe_cat = df[params[\"cat_columns\"]].describe()\n",
    "        display(df_describe_cat)\n",
    "\n",
    "    @staticmethod\n",
    "    def eda_df(df):\n",
    "        \"\"\"Провести EDA для датафрейма\"\"\"\n",
    "        df_describe = df.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "        # посчитать долю пропусков\n",
    "        df_describe.loc[\"%nan\"] = (np.round(df[df_describe.columns].isna().mean()*100, 2)).to_list()\n",
    "        # посчитать дисперсию\n",
    "        columns_var = []\n",
    "        for column in df_describe.columns:\n",
    "            columns_var.append(df[column].var())\n",
    "        df_describe.loc['var'] = columns_var\n",
    "        return df_describe\n",
    "\n",
    "    @staticmethod\n",
    "    def show_boxes(df, columns, ncols = 3, type=\"box\", row_height=500, total_width=1200):\n",
    "        \"\"\"Показать 'ящики_с_усами' для набора df.\n",
    "        Ящики будут показаны для столбцов датафрема, перечисленных в columns.\n",
    "        Графики будут показаны в несколько столбцов, количество которых задается в параметре ncols.\"\"\"\n",
    "        nrows = int(round((len(columns) + 0.5) / ncols, 0))\n",
    "        nrows = nrows if nrows > 1 else 1\n",
    "\n",
    "        if type == \"box\":\n",
    "            title = \"Ящики с усами\"\n",
    "        elif type == \"hist\":\n",
    "            title = \"Гистрограммы\"\n",
    "        elif type == \"pie\":\n",
    "            title = \"Пирожки\"\n",
    "        else:\n",
    "            raise f\"Не реализована обработка типа графика {type}\"\n",
    "\n",
    "\n",
    "        fig = plotly_subplt.make_subplots(rows=nrows, cols=ncols)\n",
    "        fig.update_layout(\n",
    "            title_x=0.5,\n",
    "            title_text=title,\n",
    "            height=row_height*nrows, \n",
    "            width=total_width\n",
    "        )\n",
    "        i = 0\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if type == \"box\":\n",
    "                    fig.add_box(y=df[columns[i]], name=columns[i], row=r+1, col=c+1)\n",
    "                elif type == \"hist\":\n",
    "                    fig.add_histogram(x=df[columns[i]], name=columns[i], row=r+1, col=c+1)\n",
    "                elif type == \"pie\":\n",
    "                    fig.add_pie(df[columns[i]].value_counts().values,\n",
    "                                labels=df[columns[i]].value_counts().index, \n",
    "                                name=columns[i], row=r+1, col=c+1)\n",
    "                else:\n",
    "                    raise f\"Не реализована обработка типа графика {type}\"\n",
    "                i += 1\n",
    "                if i >= len(columns):\n",
    "                    break\n",
    "            if i >= len(columns):\n",
    "                break\n",
    "        fig.show()          \n",
    "\n",
    "    @staticmethod\n",
    "    def show_boxes_plt(df, columns_x, ncols = 3, type=\"box\", row_height=500, total_width=1200, column_y=None, filename=None):\n",
    "        \"\"\"Показать 'ящики_с_усами' для набора df.\n",
    "        Ящики будут показаны для столбцов датафрема, перечисленных в columns.\n",
    "        Графики будут показаны в несколько столбцов, количество которых задается в параметре ncols.\"\"\"\n",
    "        nrows = int(round((len(columns_x) + 0.59) / ncols, 0))\n",
    "        nrows = nrows if nrows > 1 else 1\n",
    "\n",
    "        if type == \"box\":\n",
    "            title = \"Ящики с усами\"\n",
    "        elif type == \"hist\":\n",
    "            title = \"Гистрограммы\"\n",
    "        elif type == \"pie\":\n",
    "            title = \"Пирожки\"\n",
    "        else:\n",
    "            raise f\"Не реализована обработка типа графика {type}\"\n",
    "                \n",
    "        plt.figure(figsize=(ncols * 5, nrows * 3))\n",
    "        \n",
    "        for i, column in enumerate(columns_x, start=1):\n",
    "            plt.subplot(nrows, ncols, i)\n",
    "            if type == \"box\":\n",
    "                if column_y is None:\n",
    "                    sns.boxplot(x=df[column])\n",
    "                else:\n",
    "                    sns.boxplot(x=df[column], y=df[column_y])\n",
    "            elif type == \"hist\":\n",
    "                sns.histplot(df[column], kde=True)\n",
    "            elif type == \"pie\":\n",
    "                # define Seaborn color palette to use \n",
    "                palette_color = sns.color_palette(\"pastel\") \n",
    "                # plotting data on chart \n",
    "                plt.pie(x=df[column].value_counts().values, \n",
    "                        labels=df[column].value_counts().index, \n",
    "                        colors=palette_color, autopct='%.0f%%') \n",
    "            else:\n",
    "                raise f\"Не реализована обработка типа графика {type}\"\n",
    "            # Добавить название столбца как заголовок графика\n",
    "            plt.title(column)\n",
    "        plt.tight_layout()\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename, dpi=300)\n",
    "        else:\n",
    "            plt.show()\n",
    "            \n",
    "    @staticmethod            \n",
    "    def iqr_values(values):\n",
    "        \"\"\"Границы для ящика-с-усами\n",
    "        Возвращаемые значения: Q1, Q3, IQR, lower, upper\n",
    "        \"\"\"\n",
    "        Q3 = np.quantile(values, 0.75, axis=0)\n",
    "        Q1 = np.quantile(values, 0.25, axis=0)\n",
    "        IQR = Q3 - Q1\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        return Q1, Q3, IQR, lower, upper\n",
    "\n",
    "        \n",
    "    @staticmethod    \n",
    "    def nans_percents(df):\n",
    "        return df.isna().sum()/len(df)*100    \n",
    "\n",
    "    @staticmethod\n",
    "    def encode_features(src_df, onehot_cols=None, onehot_drop=None, ordinal_cols=None, columns_X=None):\n",
    "        df = src_df.copy()  \n",
    "        new_columns_X = copy.deepcopy(columns_X)\n",
    "        if onehot_cols is not None:\n",
    "            encoder = OneHotEncoder(sparse_output=False, drop=onehot_drop)\n",
    "            one_hot_encoded = encoder.fit_transform(df[onehot_cols])\n",
    "            one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(onehot_cols))\n",
    "            df = pd.concat([df, one_hot_df], axis=1)\n",
    "            new_columns_X += encoder.get_feature_names_out(onehot_cols).tolist()\n",
    "            for col in onehot_cols:\n",
    "                if col in columns_X:\n",
    "                    new_columns_X.remove(col)\n",
    "            df.drop(onehot_cols, axis=1, inplace=True)\n",
    "            \n",
    "        if ordinal_cols is not None:\n",
    "            ordinal_columns_cats = list(ordinal_cols.values())\n",
    "            ordinal_columns_list = list(ordinal_cols.keys())\n",
    "            encoder = OrdinalEncoder(categories = ordinal_columns_cats)\n",
    "            df[ordinal_columns_list] = encoder.fit_transform(df[ordinal_columns_list])  \n",
    "\n",
    "        return df, new_columns_X\n",
    "\n",
    "    @staticmethod\n",
    "    def fill_with_mode(data, group_col, target_col):\n",
    "        \"\"\"Заполнить target_col модой внутри каждой группы столбцов group_col\"\"\"\n",
    "        global_mode = data[target_col].mode()[0]\n",
    "        def fill_group_mode(x):\n",
    "            group_mode = x.mode()\n",
    "            if not group_mode.empty:\n",
    "                return group_mode[0]\n",
    "            else:\n",
    "                return global_mode\n",
    "        data[target_col] = data.groupby(group_col)[target_col].transform(fill_group_mode)\n",
    "\n",
    "    @staticmethod   \n",
    "    def fill_with_mean(data, group_col, target_col):\n",
    "        \"\"\"Заполнить target_col средним внутри каждой группы столбцов group_col\"\"\"\n",
    "        def fill_group_mean(x):\n",
    "            return x.mean()\n",
    "        data[target_col] = data.groupby(group_col)[target_col].transform(fill_group_mean)    \n",
    "        # заполним глобальным средним, если что-то пропустилось\n",
    "        data.fillna({target_col: data[target_col].mean()}, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_dataset(dataset_df, params, scaler=None, train_size=0.7):\n",
    "        \"\"\"Разделить датасет на тренировочную и тестовую выборки и прогнать через нормализатор, если он указан\"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset_df[params[\"columns_X\"]], \n",
    "                                                            dataset_df[params[\"target_column\"]], \n",
    "                                                            train_size=train_size, \n",
    "                                                            stratify=dataset_df[params[\"target_column\"]],\n",
    "                                                            random_state=42)\n",
    "        # Нормировка признаков\n",
    "        if scaler is not None:\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def find_rows_with_nan(dataset_df, columns, debug=False):\n",
    "        # сначала посмотрим на столбцы с измерениями \n",
    "        all_rows_with_nan = []\n",
    "        rows_with_all_columns_nan = []\n",
    "        for column in columns:\n",
    "            nan_rows = dataset_df[dataset_df[column].isna()].index.to_list()\n",
    "            if debug:\n",
    "                print(f'Индексы строк с пустым {column}: {nan_rows}')\n",
    "            all_rows_with_nan += nan_rows\n",
    "            if rows_with_all_columns_nan == []:\n",
    "                rows_with_all_columns_nan = nan_rows\n",
    "            else:\n",
    "                rows_with_all_columns_nan = list(set(rows_with_all_columns_nan) & set(nan_rows))\n",
    "        # получить уникальный список индексов с пустыми столбцами\n",
    "        all_rows_with_nan = list(set(all_rows_with_nan))    \n",
    "        return rows_with_all_columns_nan, all_rows_with_nan        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class Settings():\n",
    "    enviroment: object\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.dataset_folder = str(Path(Path.cwd(), self.enviroment[\"DATASET_SUBFOLDER\"]))\n",
    "        self.cache_folder = str(Path(Path.cwd(), self.enviroment[\"CACHE_SUBFOLDER\"]))\n",
    "        self.result_folder = str(Path(Path.cwd(), self.enviroment[\"RESULT_SUBFOLDER\"]))\n",
    "        \n",
    "    def cache_gridsearch_filename(self, model_name): \n",
    "        return Path(self.cache_folder, self.enviroment[\"GRID_SEARCH_TEMPLATE_FILENAME\"] % model_name)\n",
    "    def cache_model_filename(self, model_name): \n",
    "        return Path(self.cache_folder, self.enviroment[\"MODEL_CLASS_TEMPLATE_FILENAME\"] % model_name)\n",
    "    def result_gridsearch_filename(self, model_name): \n",
    "        return Path(self.result_folder, self.enviroment[\"GRID_SEARCH_TEMPLATE_FILENAME\"] % model_name) \n",
    "    def result_model_filename(self, model_name): \n",
    "        return Path(self.result_folder, self.enviroment[\"MODEL_CLASS_TEMPLATE_FILENAME\"] % model_name)\n",
    "    def result_trained_model_filename(self, model_name): \n",
    "        return Path(self.result_folder, self.enviroment[\"MODEL_CLASS_TEMPLATE_FILENAME\"] % f'{model_name}_trained')             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelWrapBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapBase(abc.ABC):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.model_params = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "    def create_model(self, model_class, model_params, X_train, X_test, y_train, y_test):\n",
    "        self.model_params = model_params\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.model = model_class(**self.model_params)\n",
    "    \n",
    "    def fit(self):\n",
    "        self.model.fit(self.X_train, self.y_train)    \n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def calc_metrics(self):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def show_quality(self): \n",
    "        raise NotImplemented\n",
    "    \n",
    "    @staticmethod\n",
    "    def metrics_names():\n",
    "        raise NotImplemented\n",
    "    \n",
    "    @staticmethod\n",
    "    def metrics(self):\n",
    "        raise NotImplemented\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_or_create_and_fit_model(model_meta_class, \n",
    "                                      model_name, model_class, model_params, \n",
    "                                      X_train, X_test, y_train, y_test,\n",
    "                                      settings, \n",
    "                                      need_save=True):\n",
    "        \"\"\"Загрузить ранее обученную модель из кеша.\n",
    "        Если в кеше нет - обучить на переданных данных с заданными параметрами.\n",
    "        \"\"\"\n",
    "        model_filename_cache = settings.cache_model_filename(model_name)\n",
    "        model_filename = settings.result_model_filename(model_name)\n",
    "\n",
    "        if Path.is_file(model_filename_cache):\n",
    "            model = joblib.load(model_filename_cache)\n",
    "            print(f\"Модель {type(model.model).__name__} загружена из {model_filename_cache}\")\n",
    "        else:\n",
    "            print(f\"Создается и тренируется модель {model_name} класса {type(model_class).__name__}\")\n",
    "            print(f'Гиперпараметры модели: {model_params}')\n",
    "            model = model_meta_class(model_name)\n",
    "            model.create_model(model_class, model_params, X_train, X_test, y_train, y_test)\n",
    "            model.fit()\n",
    "            model.calc_metrics()\n",
    "            if need_save:\n",
    "                print(f\"\\nКласс-обвертка модели сохранен в {model_filename}\")\n",
    "                _ = joblib.dump(model, model_filename)\n",
    "                print(f\"\\nНатренированная модель сохранена в {settings.result_trained_model_filename(model_name)}\")\n",
    "                _= joblib.dump(model.model, settings.result_trained_model_filename(model_name))\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_or_create_and_fit_GridSearchCV(model_name, model_class, param_grid, X_train, y_train,\n",
    "                                             settings, \n",
    "                                             scoring='roc_auc', \n",
    "                                             need_save=True, n_jobs=None, verbose=1,\n",
    "                                             use_randomize_search = True, n_iter=100):\n",
    "        \"\"\"Загрузить ранее обученные GridSearchCV из кеша. \n",
    "        Если в кеше нет - создать и потренировать, найдя лучшие гиперпараметры\"\"\"\n",
    "        \n",
    "        \n",
    "        grid_search_filename_cache = settings.cache_gridsearch_filename(model_name)\n",
    "        grid_search_filename = settings.result_gridsearch_filename(model_name)\n",
    "\n",
    "        if Path.is_file(grid_search_filename_cache):\n",
    "            print(f\"GridSearchCV() загружен из {grid_search_filename_cache}\")\n",
    "            grid_search = joblib.load(grid_search_filename_cache)\n",
    "        else:\n",
    "            if use_randomize_search:\n",
    "                print(f\"Создается и выполняется RandomizedSearchCV для модели {model_name} класса {model_class.__name__}\")\n",
    "                grid_search = RandomizedSearchCV(model_class(), param_grid, cv=5, n_jobs=n_jobs, \n",
    "                                                 verbose=verbose, scoring=scoring,\n",
    "                                                 random_state=settings.enviroment[\"RANDOM_STATE\"],\n",
    "                                                 n_iter=n_iter)\n",
    "            else:\n",
    "                print(f\"Создается и выполняется GridSearchCV для модели {model_name} класса {model_class.__name__}\")\n",
    "                grid_search = GridSearchCV(model_class(), param_grid, cv=5, n_jobs=n_jobs, \n",
    "                                           verbose=verbose, scoring=scoring)\n",
    "            \n",
    "            # Обучаем модель на данных с использованием кросс-валидации\n",
    "            grid_search.fit(X_train, y_train)\n",
    "        \n",
    "            if need_save:\n",
    "                print(f\"\\nРезультаты поиска оптимальных гиперпараметров модели сохранены в {grid_search_filename}\")\n",
    "                _ = joblib.dump(grid_search, grid_search_filename)\n",
    "        return grid_search    \n",
    "    \n",
    "    @staticmethod\n",
    "    def compare_metrcis(model_wraps):\n",
    "        \"\"\"Сформировать датафрейм с метриками моделей из списка model_wraps\"\"\"\n",
    "        df_metrics = []\n",
    "        for model_wrap in model_wraps:\n",
    "            df_metrics.append(pd.DataFrame(model_wrap.metrics()))\n",
    "\n",
    "        df_stat = pd.concat(df_metrics)\n",
    "        columns = ['model_name']\n",
    "        columns = columns + model_wraps[0].metrics_names()\n",
    "        df_stat2 = df_stat.pivot_table(columns = 'params',\n",
    "                                        index='model_name',\n",
    "                                        values='values').reset_index()[columns]\n",
    "        return df_stat2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelWrapRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы метрик для оценки моделей регрессии\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,  # Средняя квадратичная ошибка для регрессии\n",
    "    mean_absolute_error, \n",
    "    root_mean_squared_error, \n",
    "    r2_score  # Коэффициент детерминации для регрессии\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapRegression(ModelWrapBase):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.mse_train = None\n",
    "        self.r2_train = None\n",
    "        self.rmse_train = None\n",
    "        self.mae_train = None\n",
    "\n",
    "        self.mse_test = None\n",
    "        self.r2_test = None\n",
    "        self.rmse_test = None\n",
    "        self.mae_test = None\n",
    "\n",
    "    def calc_metrics(self):\n",
    "        \"\"\"Посчитать метрики модели\"\"\"\n",
    "        self.y_train_pred = self.model.predict(self.X_train)\n",
    "        self.y_test_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        self.mse_train = mean_squared_error(self.y_train, self.y_train_pred)\n",
    "        self.r2_train = r2_score(self.y_train, self.y_train_pred)\n",
    "        self.rmse_train = root_mean_squared_error(self.y_train, self.y_train_pred)\n",
    "        self.mae_train = mean_absolute_error(self.y_train, self.y_train_pred)   \n",
    "        self.median_train = self.y_train.median() \n",
    "\n",
    "        self.mse_test = mean_squared_error(self.y_test, self.y_test_pred)\n",
    "        self.r2_test = r2_score(self.y_test, self.y_test_pred)\n",
    "        self.rmse_test = root_mean_squared_error(self.y_test, self.y_test_pred)\n",
    "        self.mae_test = mean_absolute_error(self.y_test, self.y_test_pred)    \n",
    "        self.median_test = self.y_test.median() \n",
    "    \n",
    "        \n",
    "    def show_quality(self): \n",
    "        \"\"\"Показать различные метрики\"\"\"\n",
    "        print('Train data:')\n",
    "        print(f\"  MSE:    {round(self.mse_train,4)}\")\n",
    "        print(f\"  RMSE:   {round(self.rmse_train,4)}\")\n",
    "        print(f\"  MAE:    {round(self.mae_train,4)}\")\n",
    "        print(f\"  r2:     {round(self.r2_train,4)}\")\n",
    "        print(f\"  median: {round(self.median_train,4)}\")\n",
    "\n",
    "        print('Test data:')\n",
    "        print(f\"  MSE:    {round(self.mse_test,4)}\")\n",
    "        print(f\"  RMSE:   {round(self.rmse_test,4)}\")\n",
    "        print(f\"  MAE:    {round(self.mae_test,4)}\")\n",
    "        print(f\"  r2:     {round(self.r2_test,4)}\")    \n",
    "        print(f\"  median: {round(self.median_train,4)}\")        \n",
    "    \n",
    "    @staticmethod\n",
    "    def metrics_names():\n",
    "        return ['Train_MSE', 'Test_MSE',\n",
    "                'Train_RMSE', 'Test_RMSE',\n",
    "                'Train_MAE', 'Test_MAE',\n",
    "                'Train_R2', 'Test_R2',\n",
    "                'Train_median', 'Test_Median'\n",
    "                ]\n",
    "    \n",
    "    def metrics(self):\n",
    "        \"\"\"Сформировать словарь о сзначениями метрик модели\"\"\"\n",
    "        metrics_as_dict = {\n",
    "                'params': ModelWrapRegression.metrics_names(),\n",
    "                'values': [\n",
    "                    self.mse_train, self.mse_test,\n",
    "                    self.rmse_train, self.rmse_test,\n",
    "                    self.mae_train, self.mae_test,\n",
    "                    self.r2_train, self.r2_test,\n",
    "                    self.median_train, self.median_train\n",
    "                ],\n",
    "                'model_name': [self.name for i in range(len(ModelWrapRegression.metrics_names()))]\n",
    "            }      \n",
    "        return metrics_as_dict\n",
    "\n",
    "    @staticmethod    \n",
    "    def load_or_create_and_fit_model(model_name, model_class, model_params, \n",
    "                                    X_train, X_test, y_train, y_test,\n",
    "                                    settings, \n",
    "                                    need_save=True):\n",
    "        \"\"\"Загрузить ранее обученную модель из кеша.\n",
    "        Если в кеше нет - обучить на переданных данных с заданными параметрами.\n",
    "        \"\"\"\n",
    "        return ModelWrapBase._load_or_create_and_fit_model(ModelWrapRegression, \n",
    "                                                       model_name, model_class, model_params, \n",
    "                                                       X_train, X_test, y_train, y_test,\n",
    "                                                       settings, \n",
    "                                                       need_save)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelWrapClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы метрик для оценки моделей классификации\n",
    "from sklearn.metrics import (\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    roc_auc_score, \n",
    "    roc_curve, \n",
    "    f1_score,  #f1-мера\n",
    "    accuracy_score,  # Метрика точности для классификации\n",
    "    classification_report,  # Отчет о классификации\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapClass(ModelWrapBase):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "        self.train_precision = None\n",
    "        self.test_precision = None\n",
    "        self.train_recall = None\n",
    "        self.test_recall = None\n",
    "        self.train_roc_auc = None\n",
    "        self.test_roc_auc = None\n",
    "        self.train_accuracy = None\n",
    "        self.test_accuracy = None\n",
    "        self.train_f1_score = None\n",
    "        self.test_f1_score = None\n",
    "        self.specific_data = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.y_train_proba = None\n",
    "        self.y_test_proba = None\n",
    "\n",
    "    def calc_metrics(self):\n",
    "        \"\"\"Посчитать метрики модели\"\"\"\n",
    "        self.y_train_pred = self.model.predict(self.X_train)\n",
    "        self.y_train_prob = self.model.predict_proba(self.X_train)[:, 1]\n",
    "        self.y_test_pred = self.model.predict(self.X_test)\n",
    "        self.y_test_prob = self.model.predict_proba(self.X_test)[:, 1]\n",
    "    \n",
    "        # матрица ошибок\n",
    "        #self.conf_matrix_train = confusion_matrix(self.y_train, self.y_train_pred)\n",
    "        #self.conf_matrix_test = confusion_matrix(self.y_test, self.y_test_pred)\n",
    "        #self.conf_matrix_norm_train = confusion_matrix(self.y_train, self.y_train_pred, normalize='all')\n",
    "        #self.conf_matrix_norm_test = confusion_matrix(self.y_test, self.y_test_pred, normalize='all')\n",
    "        \n",
    "\n",
    "        # Расчет AUC-ROC\n",
    "        self.train_roc_auc = roc_auc_score(self.y_train, self.y_train_prob)\n",
    "        self.test_roc_auc = roc_auc_score(self.y_test, self.y_test_prob)\n",
    "\n",
    "        # Поиск порога, максимизирующего F1-score\n",
    "        thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "        f1_scores = [f1_score(self.y_test, self.y_test_prob >= t) for t in thresholds]\n",
    "        self.optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "        # Пересчет метрик с учетом оптимального порога\n",
    "        self.y_train_pred_optimal = (self.y_train_prob >= self.optimal_threshold).astype(int)\n",
    "        self.y_test_pred_optimal = (self.y_test_prob >= self.optimal_threshold).astype(int)\n",
    "\n",
    "        self.train_precision = precision_score(self.y_train, self.y_train_pred_optimal)\n",
    "        self.test_precision = precision_score(self.y_test, self.y_test_pred_optimal)\n",
    "\n",
    "        self.train_recall = recall_score(self.y_train, self.y_train_pred_optimal)\n",
    "        self.test_recall = recall_score(self.y_test, self.y_test_pred_optimal)\n",
    "\n",
    "        self.train_accuracy = accuracy_score(self.y_train, self.y_train_pred_optimal)\n",
    "        self.test_accuracy = accuracy_score(self.y_test, self.y_test_pred_optimal)\n",
    "\n",
    "        self.train_f1_score = f1_score(self.y_train, self.y_train_pred_optimal)\n",
    "        self.test_f1_score = f1_score(self.y_test, self.y_test_pred_optimal)\n",
    "        \n",
    "    def show_quality(self): #X_train, X_test, y_train, y_test, check_result, title, grid_search, model_cl):\n",
    "        \"\"\"Показать различные метрики и промежуточные переменные обучения\"\"\"\n",
    "        #def show_quality2(X_train, X_test, y_train, y_test, check_result, title, grid_search, model_cl):\n",
    "        fig = plotly_subplt.make_subplots(rows=2, cols=2, \n",
    "                                        subplot_titles=['ROC AUC', 'Metrics', 'Confusion Matrix Train', 'Confusion Matrix Test'],\n",
    "                                        vertical_spacing = 0.1,\n",
    "                                        row_width=[0.4, 0.6])\n",
    "        fig.update_layout(\n",
    "            title_x=0.5,\n",
    "            title_text=self.name,\n",
    "            width = 1000,\n",
    "            height = 800,\n",
    "            legend = dict(yanchor=\"bottom\", y=0.63, xanchor=\"right\", x=0.44),\n",
    "            margin = {'t':80, 'b':50, 'l':10, 'r':10}\n",
    "            \n",
    "        )\n",
    "\n",
    "        # Построение ROC кривой\n",
    "        fpr_test, tpr_test, thresholds = roc_curve(self.y_test, self.y_test_prob)\n",
    "        fpr_train, tpr_train, thresholds = roc_curve(self.y_train, self.y_train_prob)\n",
    "        roc_train_g = plotly_go.Scatter(x=fpr_train, y=tpr_train, name=\"ROC curve Train\", line={'color':'green'})\n",
    "        roc_test_g = plotly_go.Scatter(x=fpr_test, y=tpr_test, name=\"ROC curve Test\", line={'color':'blue'})\n",
    "        roc_diag_g = plotly_go.Scatter(x=[0, 1], y=[0, 1], line={'color':'gray', 'dash': 'dash'}, showlegend=False)\n",
    "\n",
    "        fig.add_trace(roc_train_g, row=1, col=1)\n",
    "        fig.add_trace(roc_test_g, row=1, col=1)\n",
    "        fig.add_trace(roc_diag_g, row=1, col=1)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            xaxis1 = {'title_text': \"False Positive Rate\"},\n",
    "            yaxis1 = {'title_text': \"True Positive Rate\"}\n",
    "        )    \n",
    "        \n",
    "\n",
    "        # Bar с метриками\n",
    "        df_metrics = pd.DataFrame([[self.test_accuracy,  self.train_accuracy],\n",
    "                                   [self.test_precision, self.train_precision],\n",
    "                                   [self.test_recall,    self.train_recall],\n",
    "                                   [self.test_roc_auc,   self.train_roc_auc],\n",
    "                                   [self.test_f1_score,  self.train_f1_score]], \n",
    "                                  columns = [\"Test\", \"Train\"], \n",
    "                                  index=[\"accuracy\", \"precision\", \"recall\", \"ROC AUC\", \"F1\"])\n",
    "        metrics_train = plotly_go.Bar(x=df_metrics.index, y=df_metrics.Train, \n",
    "                        showlegend=True, text=round(df_metrics.Train,4), textangle=0, \n",
    "                        xaxis='x2', yaxis='y2', name=\"Train Metrics\")\n",
    "        metrics_test = plotly_go.Bar(x=df_metrics.index, y=df_metrics.Test, \n",
    "                        showlegend=True, text=round(df_metrics.Test,4), textangle=0, \n",
    "                        xaxis='x2', yaxis='y2', name=\"Test Metrics\")\n",
    "\n",
    "        fig.add_trace(metrics_train, row=1, col=2) \n",
    "        fig.add_trace(metrics_test, row=1, col=2) \n",
    "\n",
    "        # Confusion Matrix \n",
    "        \"\"\"\n",
    "        cm_normalized_train = self.conf_matrix_train.astype('float') / self.conf_matrix_train.sum(axis=1)[:, np.newaxis]\n",
    "        print(self.conf_matrix_train.astype('float'))\n",
    "        print(self.conf_matrix_train.sum(axis=1).astype('float'))\n",
    "        print(cm_normalized_train)\n",
    "        heatmap_train = plotly_go.Heatmap(z=cm_normalized_train, x=['0', '1'], y=['0', '1'], colorscale='Blues', \n",
    "                                        text=np.round(cm_normalized_train, 3), texttemplate=\"%{text}\", showscale=False)\n",
    "\n",
    "        cm_normalized_test = self.conf_matrix_test.astype('float') / self.conf_matrix_test.sum(axis=1)[:, np.newaxis]\n",
    "        heatmap_test = plotly_go.Heatmap(z=cm_normalized_test, x=['0', '1'], y=['0', '1'], colorscale='Blues', \n",
    "                                        text=np.round(cm_normalized_test, 3), texttemplate=\"%{text}\", showscale=False)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        train_cm = confusion_matrix(self.y_train, self.y_train_pred_optimal, normalize='all')\n",
    "        heatmap_train = plotly_go.Heatmap(z=train_cm, \n",
    "                                          x=['0', '1'], y=['0', '1'], \n",
    "                                          colorscale='Blues', \n",
    "                                          text=np.round(train_cm, 3), \n",
    "                                          texttemplate=\"%{text}\", \n",
    "                                          showscale=False)\n",
    "\n",
    "        test_cm = confusion_matrix(self.y_test, self.y_test_pred_optimal, normalize='all')\n",
    "        heatmap_test = plotly_go.Heatmap(z=test_cm, \n",
    "                                         x=['0', '1'], y=['0', '1'], \n",
    "                                         colorscale='Blues', \n",
    "                                         text=np.round(test_cm, 3), \n",
    "                                         texttemplate=\"%{text}\", \n",
    "                                         showscale=False)\n",
    "\n",
    "\n",
    "        fig.add_trace(heatmap_train, row=2, col=1)\n",
    "        fig.add_trace(heatmap_test,  row=2, col=2) \n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis1 = {'title': 'Predict'},\n",
    "            xaxis2 = {'title': 'Predict'},\n",
    "            yaxis1 = {'title': 'Goals'},\n",
    "            yaxis2 = {'title': 'Goals'},\n",
    "            xaxis3 = {'title': 'Предсказания'},\n",
    "            xaxis4 = {'title': 'Предсказания'},\n",
    "            yaxis3 = {'title': 'Факт'},\n",
    "            yaxis4 = {'title': 'Факт'},\n",
    "                        \n",
    "        )    \n",
    "        \n",
    "        fig.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def metrics_names():\n",
    "        return ['Training_Precision', 'Test_Precision',\n",
    "                'Training_Recall', 'Test_Recall',\n",
    "                'ROC_AUC_Train', 'ROC_AUC_Test',\n",
    "                'Accuarcy_Train', 'Accuarcy_Test',\n",
    "                'F1_score_Train', 'F1_score_Test'\n",
    "                ]\n",
    "    \n",
    "    def metrics(self):\n",
    "        \"\"\"Сформировать словарь о сзначениями метрик модели\"\"\"\n",
    "        metrics_as_dict = {\n",
    "                'params': ModelWrapClass.metrics_names(),\n",
    "                'values': [\n",
    "                    self.train_precision, self.test_precision,\n",
    "                    self.train_recall, self.test_recall,\n",
    "                    self.train_roc_auc, self.test_roc_auc,\n",
    "                    self.train_accuracy, self.test_accuracy,\n",
    "                    self.train_f1_score, self.test_f1_score\n",
    "                ],\n",
    "                'model_name': [self.name for i in range(len(ModelWrapClass.metrics_names()))]\n",
    "            }      \n",
    "        return metrics_as_dict\n",
    "\n",
    "    @staticmethod    \n",
    "    def load_or_create_and_fit_model(model_name, model_class, model_params, \n",
    "                                    X_train, X_test, y_train, y_test,\n",
    "                                    settings, \n",
    "                                    need_save=True):\n",
    "        \"\"\"Загрузить ранее обученную модель из кеша.\n",
    "        Если в кеше нет - обучить на переданных данных с заданными параметрами.\n",
    "        \"\"\"\n",
    "        return ModelWrapBase._load_or_create_and_fit_model(ModelWrapClass, \n",
    "                                                       model_name, model_class, model_params, \n",
    "                                                       X_train, X_test, y_train, y_test,\n",
    "                                                       settings, \n",
    "                                                       need_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapRegression(ModelWrapBase):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.mse_train = None\n",
    "        self.r2_train = None\n",
    "        self.rmse_train = None\n",
    "        self.mae_train = None\n",
    "\n",
    "        self.mse_test = None\n",
    "        self.r2_test = None\n",
    "        self.rmse_test = None\n",
    "        self.mae_test = None\n",
    "\n",
    "    def calc_metrics(self):\n",
    "        \"\"\"Посчитать метрики модели\"\"\"\n",
    "        self.y_train_pred = self.model.predict(self.X_train)\n",
    "        self.y_test_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        self.mse_train = mean_squared_error(self.y_train, self.y_train_pred)\n",
    "        self.r2_train = r2_score(self.y_train, self.y_train_pred)\n",
    "        self.rmse_train = root_mean_squared_error(self.y_train, self.y_train_pred)\n",
    "        self.mae_train = mean_absolute_error(self.y_train, self.y_train_pred)   \n",
    "        self.median_train = self.y_train.median() \n",
    "\n",
    "        self.mse_test = mean_squared_error(self.y_test, self.y_test_pred)\n",
    "        self.r2_test = r2_score(self.y_test, self.y_test_pred)\n",
    "        self.rmse_test = root_mean_squared_error(self.y_test, self.y_test_pred)\n",
    "        self.mae_test = mean_absolute_error(self.y_test, self.y_test_pred)    \n",
    "        self.median_test = self.y_test.median() \n",
    "    \n",
    "        \n",
    "    def show_quality(self): \n",
    "        \"\"\"Показать различные метрики\"\"\"\n",
    "        print('Train data:')\n",
    "        print(f\"  MSE:    {round(self.mse_train,4)}\")\n",
    "        print(f\"  RMSE:   {round(self.rmse_train,4)}\")\n",
    "        print(f\"  MAE:    {round(self.mae_train,4)}\")\n",
    "        print(f\"  r2:     {round(self.r2_train,4)}\")\n",
    "        print(f\"  median: {round(self.median_train,4)}\")\n",
    "\n",
    "        print('Test data:')\n",
    "        print(f\"  MSE:    {round(self.mse_test,4)}\")\n",
    "        print(f\"  RMSE:   {round(self.rmse_test,4)}\")\n",
    "        print(f\"  MAE:    {round(self.mae_test,4)}\")\n",
    "        print(f\"  r2:     {round(self.r2_test,4)}\")    \n",
    "        print(f\"  median: {round(self.median_train,4)}\")        \n",
    "    \n",
    "    @staticmethod\n",
    "    def metrics_names():\n",
    "        return ['Train_MSE', 'Test_MSE',\n",
    "                'Train_RMSE', 'Test_RMSE',\n",
    "                'Train_MAE', 'Test_MAE',\n",
    "                'Train_R2', 'Test_R2',\n",
    "                'Train_median', 'Test_Median'\n",
    "                ]\n",
    "    \n",
    "    def metrics(self):\n",
    "        \"\"\"Сформировать словарь о сзначениями метрик модели\"\"\"\n",
    "        metrics_as_dict = {\n",
    "                'params': ModelWrapRegression.metrics_names(),\n",
    "                'values': [\n",
    "                    self.mse_train, self.mse_test,\n",
    "                    self.rmse_train, self.rmse_test,\n",
    "                    self.mae_train, self.mae_test,\n",
    "                    self.r2_train, self.r2_test,\n",
    "                    self.median_train, self.median_train\n",
    "                ],\n",
    "                'model_name': [self.name for i in range(len(ModelWrapRegression.metrics_names()))]\n",
    "            }      \n",
    "        return metrics_as_dict\n",
    "\n",
    "    @staticmethod    \n",
    "    def load_or_create_and_fit_model(model_name, model_class, model_params, \n",
    "                                    X_train, X_test, y_train, y_test,\n",
    "                                    settings, \n",
    "                                    need_save=True):\n",
    "        \"\"\"Загрузить ранее обученную модель из кеша.\n",
    "        Если в кеше нет - обучить на переданных данных с заданными параметрами.\n",
    "        \"\"\"\n",
    "        return ModelWrapBase._load_or_create_and_fit_model(ModelWrapRegression, \n",
    "                                                       model_name, model_class, model_params, \n",
    "                                                       X_train, X_test, y_train, y_test,\n",
    "                                                       settings, \n",
    "                                                       need_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конфигурирование среды и окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 50) # Устанавливаем максимальное количество отображаемых столбцов равным 50\n",
    "#pd.set_option('display.max_rows', 50) # Устанавливаем максимальное количество отображаемых строк равным 20\n",
    "pd.options.display.float_format = '{:.5f}'.format # Устанавливаем формат отображения чисел с двумя знаками после запятой\n",
    "pd.options.mode.use_inf_as_na = True # Настройка режима Pandas для рассмотрения бесконечностей (inf) как пропущенных значений (NA)\n",
    "\n",
    "# Конфигурация формата отображения графиков в виде векторных изображений\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# для построения графиков внутри Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_filename = \"settings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(settings_filename).exists():\n",
    "    with open(settings_filename, \"w\") as f:\n",
    "        f.write(\"\"\"# Каталог с датасетом\n",
    "DATASET_SUBFOLDER=dataset\n",
    "# Каталог для результатов и промежуточных файлов\n",
    "RESULT_SUBFOLDER=result\n",
    "# Каталог для кеша промежуточных результатов\n",
    "CACHE_SUBFOLDER=cached_results\n",
    "# Каталог для boxplot\n",
    "BOXPLOT_SUBFOLDER=boxplot\n",
    "\n",
    "RANDOM_STATE=42\n",
    "\n",
    "DATASET_FILENAME_TEMPLATE=dataset_df_%s.joblib\n",
    "PARAMS_FILENAME_TEMPLATE=params_%s.joblib\n",
    "\n",
    "X_Train_FILENAME_TEMPLATE=X_Train_%s.joblib\n",
    "y_Train_FILENAME_TEMPLATE=y_Train_%s.joblib\n",
    "X_Test_FILENAME_TEMPLATE=X_Test_%s.joblib\n",
    "y_Test_FILENAME_TEMPLATE=y_Test_%s.joblib\n",
    "\n",
    "\n",
    "# Шаблоны для имен\n",
    "GRID_SEARCH_TEMPLATE_FILENAME=03_GridSearch_%s.joblib\n",
    "MODEL_CLASS_TEMPLATE_FILENAME=04_model_%s.joblib\"\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузить параметры\n",
    "settings_dict = {\n",
    "    **dotenv_values(settings_filename)\n",
    "}\n",
    "\n",
    "settings = Settings(settings_dict)\n",
    "settings.enviroment[\"RANDOM_STATE\"] = int(settings.enviroment[\"RANDOM_STATE\"])\n",
    "n_jobs = -1\n",
    "verbose = 2\n",
    "load_from_kaggle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузить датасет если его нет\n",
    "csv_filename = Path(settings.enviroment[\"DATASET_SUBFOLDER\"], \"smoker-status-prediction-using-biosignals\", 'train_dataset.csv')\n",
    "if not Path(csv_filename).exists():\n",
    "    if not Path(settings.enviroment[\"DATASET_SUBFOLDER\"]).exists():\n",
    "        Path.mkdir(Path(settings.enviroment[\"DATASET_SUBFOLDER\"]))\n",
    "    od.download_kaggle_dataset(\"https://www.kaggle.com/datasets/gauravduttakiit/smoker-status-prediction-using-biosignals?select=train_dataset.csv\", \n",
    "                               Path(settings.enviroment[\"DATASET_SUBFOLDER\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим датасет и для ДЗ отберем 5000 строк из датасета\n",
    "original_dataset_df = pd.read_csv(csv_filename)\n",
    "dataset_df = original_dataset_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обзор датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.sample(7, random_state=settings.enviroment[\"RANDOM_STATE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = DataSetLib.columns_by_type(dataset_df, \"smoking\")\n",
    "DataSetLib.describe_columns(dataset_df, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков в данных нет.\n",
    "\n",
    "Три переменных (\"hearing(left)\", \"hearing(right)\", \"dental caries\") выглядят как категориальные - имеют бинарные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доли значений целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataset_df[\"smoking\"].value_counts(normalize=True))\n",
    "plotly_px.bar(dataset_df[\"smoking\"].value_counts(normalize=True), \n",
    "              title=\"Доля вхождений классов в %\",\n",
    "              width=400, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы целевой переменной не очень сбалансированны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ и обработка категориальных столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSetLib.show_boxes_plt(dataset_df, params[\"cat_columns\"], ncols = 3, type=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбцы *hearing(left)* и *hearing(right)*:\n",
    "  * примерно одинаковое распределение значений в обоих столбцах: 97% - нормальный слух, 3% - с отклонениями\n",
    "  * решение: заменить на один столбец, который будет содержать объединенную информацию по обоим столбцам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка столбцов hear_left и hear_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# закодируем плохой слух (2) значением 0\n",
    "dataset_df.loc[dataset_df[\"hearing(left)\"] == 2, \"hearing(left)\"] = 0\n",
    "dataset_df.loc[dataset_df[\"hearing(right)\"] == 2, \"hearing(right)\"] = 0\n",
    "# сформируем новый столбец, содержащий информацию о качесте слуха - как сумма качества слуха обоими ушами\n",
    "dataset_df[\"hear\"] = dataset_df[\"hearing(left)\"] + dataset_df[\"hearing(right)\"]\n",
    "params[\"columns_X\"].append(\"hear\")\n",
    "params[\"cat_columns\"].append(\"hear\")\n",
    "params = DataSetLib.remove_columns(params, \"hearing(left)\")\n",
    "params = DataSetLib.remove_columns(params, \"hearing(right)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotly_px.imshow(dataset_df.corr(), height=1000, width=1000, text_auto='.2f' )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каких-то значимых корреляций в данных нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSetLib.show_boxes_plt(dataset_df, params[\"num_columns\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти во всех столбцах есть выбросы, если считать по +-1.5IQR. Но значения вполне могут быть адекватными данными.\n",
    "Тем не менее подготовим два датасета, в которых выбросы заменены на:\n",
    "  а) ближайшие крайние значения, входящие в +-1.5IQR\n",
    "  б) на медиану"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заменить выбросы на ближайшее значение, входящее в диапазон +-1.5IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_wo_outliers_minmax = dataset_df.copy(deep=True)\n",
    "for column in params[\"num_columns\"]:\n",
    "    _, _, _, lower, upper = DataSetLib.iqr_values(dataset_df[column])\n",
    "    dataset_df_wo_outliers_minmax.loc[(dataset_df_wo_outliers_minmax[column] < lower), column] = lower\n",
    "    dataset_df_wo_outliers_minmax.loc[(dataset_df_wo_outliers_minmax[column] > upper), column] = upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSetLib.show_boxes_plt(dataset_df_wo_outliers_minmax, params[\"num_columns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_minmax = DataSetLib.columns_by_type(dataset_df_wo_outliers_minmax, \"smoking\")\n",
    "DataSetLib.describe_columns(dataset_df_wo_outliers_minmax, params_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заменить выбросы на медиану"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_wo_outliers_median = dataset_df.copy(deep=True)\n",
    "for column in params[\"num_columns\"]:\n",
    "    _, _, _, lower, upper = DataSetLib.iqr_values(dataset_df[column])\n",
    "    column_median = dataset_df[column].median()\n",
    "    dataset_df_wo_outliers_median.loc[(dataset_df_wo_outliers_median[column] < lower), column] = column_median\n",
    "    dataset_df_wo_outliers_median.loc[(dataset_df_wo_outliers_median[column] > upper), column] = column_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSetLib.show_boxes_plt(dataset_df_wo_outliers_median, params[\"num_columns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_median = DataSetLib.columns_by_type(dataset_df_wo_outliers_median, \"smoking\")\n",
    "DataSetLib.describe_columns(dataset_df_wo_outliers_median, params_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель FEDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedot import Fedot\n",
    "from fedot.core.data.data import InputData #  для представления данных в формате, понятном FEDOT\n",
    "from fedot.core.data.data_split import train_test_data_setup # для разделения данных на обучающую и тестовую выборки\n",
    "from fedot.core.repository.tasks import TaskTypesEnum, Task\n",
    "\n",
    "fedot_model_name = \"fedot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = InputData.from_dataframe(dataset_df_wo_outliers_minmax[params[\"columns_X\"]],\n",
    "                                dataset_df_wo_outliers_minmax[params[\"target_column\"]],\n",
    "                                task='classification')\n",
    "fedot_train, fedot_test = train_test_data_setup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedot_model = Fedot(problem='classification', metric=['accuracy', 'roc_auc', 'precision', 'f1'], timeout=5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = BaseLib.st()\n",
    "best_pipeline = fedot_model.fit(features=fedot_train, target='target')\n",
    "fedot_durarion_fit = BaseLib.ft(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Модель: {best_pipeline.primary_nodes}')\n",
    "print(f'Параметры модели: {pformat(best_pipeline.primary_nodes[0].parameters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт метрик для оценки качества моделей классификации\n",
    "from sklearn.metrics import (\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    roc_auc_score, \n",
    "    roc_curve, \n",
    "    f1_score,  #f1-мера\n",
    "    accuracy_score,  # Метрика точности для классификации\n",
    "    classification_report,  # Отчет о классификации\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "\"\"\"Посчитать метрики модели\"\"\"\n",
    "f_y_train_pred = fedot_model.predict(features=fedot_train)\n",
    "f_y_train_prob = fedot_model.predict_proba(fedot_train) #[:, 1]\n",
    "f_y_test_pred = fedot_model.predict(features=fedot_test)\n",
    "f_y_test_prob = fedot_model.predict_proba(fedot_test) #[:, 1]\n",
    "\n",
    "# Расчет AUC-ROC\n",
    "f_train_roc_auc = roc_auc_score(fedot_train.target, f_y_train_prob)\n",
    "f_test_roc_auc = roc_auc_score(fedot_test.target, f_y_test_prob)\n",
    "                             \n",
    "# Поиск порога, максимизирующего F1-score\n",
    "f_thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "f_f1_scores = [f1_score(fedot_test.target, f_y_test_prob >= t) for t in f_thresholds]\n",
    "f_optimal_threshold = f_thresholds[np.argmax(f_f1_scores)]\n",
    "\n",
    "# Пересчет метрик с учетом оптимального порога\n",
    "f_y_train_pred_optimal = (f_y_train_prob >= f_optimal_threshold).astype(int)\n",
    "f_y_test_pred_optimal = (f_y_test_prob >= f_optimal_threshold).astype(int)\n",
    "\n",
    "f_train_precision = precision_score(fedot_train.target, f_y_train_pred_optimal)\n",
    "f_test_precision = precision_score(fedot_test.target, f_y_test_pred_optimal)\n",
    "\n",
    "f_train_recall = recall_score(fedot_train.target, f_y_train_pred_optimal)\n",
    "f_test_recall = recall_score(fedot_test.target, f_y_test_pred_optimal)\n",
    "\n",
    "f_train_accuracy = accuracy_score(fedot_train.target, f_y_train_pred_optimal)\n",
    "f_test_accuracy = accuracy_score(fedot_test.target, f_y_test_pred_optimal)\n",
    "\n",
    "f_train_f1_score = f1_score(fedot_train.target, f_y_train_pred_optimal)\n",
    "f_test_f1_score = f1_score(fedot_test.target, f_y_test_pred_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as plotly_px\n",
    "import plotly.graph_objects as plotly_go\n",
    "import plotly.subplots as plotly_subplt\n",
    "\n",
    "f_fig = plotly_subplt.make_subplots(rows=2, cols=2, \n",
    "                                subplot_titles=['ROC AUC', 'Metrics', 'Confusion Matrix Train', 'Confusion Matrix Test'],\n",
    "                                vertical_spacing = 0.1,\n",
    "                                row_width=[0.4, 0.6])\n",
    "f_fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    title_text=\"FEDOT\",\n",
    "    width = 1000,\n",
    "    height = 800,\n",
    "    legend = dict(yanchor=\"bottom\", y=0.63, xanchor=\"right\", x=0.44),\n",
    "    margin = {'t':80, 'b':50, 'l':10, 'r':10}\n",
    "    \n",
    ")\n",
    "\n",
    "# Построение ROC кривой\n",
    "fpr_test, tpr_test, f_thresholds = roc_curve(fedot_test.target, fedot_model.predict_proba(features=fedot_test))\n",
    "fpr_train, tpr_train, f_thresholds = roc_curve(fedot_train.target, fedot_model.predict_proba(features=fedot_train))\n",
    "roc_train_g = plotly_go.Scatter(x=fpr_train, y=tpr_train, name=\"ROC curve Train\", line={'color':'green'})\n",
    "roc_test_g = plotly_go.Scatter(x=fpr_test, y=tpr_test, name=\"ROC curve Test\", line={'color':'blue'})\n",
    "roc_diag_g = plotly_go.Scatter(x=[0, 1], y=[0, 1], line={'color':'gray', 'dash': 'dash'}, showlegend=False)\n",
    "\n",
    "f_fig.add_trace(roc_train_g, row=1, col=1)\n",
    "f_fig.add_trace(roc_test_g, row=1, col=1)\n",
    "f_fig.add_trace(roc_diag_g, row=1, col=1)\n",
    "\n",
    "f_fig.update_layout(\n",
    "    xaxis1 = {'title_text': \"False Positive Rate\"},\n",
    "    yaxis1 = {'title_text': \"True Positive Rate\"}\n",
    ")    \n",
    "\n",
    "# Bar с метриками\n",
    "df_metrics = pd.DataFrame([[f_test_accuracy,  f_train_accuracy],\n",
    "                            [f_test_precision, f_train_precision],\n",
    "                            [f_test_recall,    f_train_recall],\n",
    "                            [f_test_roc_auc,   f_train_roc_auc],\n",
    "                            [f_test_f1_score,  f_train_f1_score]], \n",
    "                            columns = [\"Test\", \"Train\"], \n",
    "                            index=[\"accuracy\", \"precision\", \"recall\", \"ROC AUC\", \"F1\"])\n",
    "metrics_train = plotly_go.Bar(x=df_metrics.index, y=df_metrics.Train, \n",
    "                showlegend=True, text=round(df_metrics.Train,4), textangle=0, \n",
    "                xaxis='x2', yaxis='y2', name=\"Train Metrics\")\n",
    "metrics_test = plotly_go.Bar(x=df_metrics.index, y=df_metrics.Test, \n",
    "                showlegend=True, text=round(df_metrics.Test,4), textangle=0, \n",
    "                xaxis='x2', yaxis='y2', name=\"Test Metrics\")\n",
    "\n",
    "f_fig.add_trace(metrics_train, row=1, col=2) \n",
    "f_fig.add_trace(metrics_test, row=1, col=2) \n",
    "\n",
    "train_cm = confusion_matrix(fedot_train.target, f_y_train_pred_optimal, normalize='all')\n",
    "heatmap_train = plotly_go.Heatmap(z=train_cm, \n",
    "                                    x=['0', '1'], y=['0', '1'], \n",
    "                                    colorscale='Blues', \n",
    "                                    text=np.round(train_cm, 3), \n",
    "                                    texttemplate=\"%{text}\", \n",
    "                                    showscale=False)\n",
    "\n",
    "test_cm = confusion_matrix(fedot_test.target, f_y_test_pred_optimal, normalize='all')\n",
    "heatmap_test = plotly_go.Heatmap(z=test_cm, \n",
    "                                    x=['0', '1'], y=['0', '1'], \n",
    "                                    colorscale='Blues', \n",
    "                                    text=np.round(test_cm, 3), \n",
    "                                    texttemplate=\"%{text}\", \n",
    "                                    showscale=False)\n",
    "\n",
    "\n",
    "f_fig.add_trace(heatmap_train, row=2, col=1)\n",
    "f_fig.add_trace(heatmap_test,  row=2, col=2) \n",
    "\n",
    "f_fig.update_layout(\n",
    "    xaxis1 = {'title': 'Predict'},\n",
    "    xaxis2 = {'title': 'Predict'},\n",
    "    yaxis1 = {'title': 'Goals'},\n",
    "    yaxis2 = {'title': 'Goals'},\n",
    "    xaxis3 = {'title': 'Предсказания'},\n",
    "    xaxis4 = {'title': 'Предсказания'},\n",
    "    yaxis3 = {'title': 'Факт'},\n",
    "    yaxis4 = {'title': 'Факт'},\n",
    "                \n",
    ")    \n",
    "f_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedot_metrics_as_dict = {'params': ModelWrapClass.metrics_names(),\n",
    "                'values': [\n",
    "                    f_train_precision, f_test_precision,\n",
    "                    f_train_recall,    f_test_recall,\n",
    "                    f_train_roc_auc,   f_test_roc_auc,\n",
    "                    f_train_accuracy,  f_test_accuracy,\n",
    "                    f_train_f1_score,  f_test_f1_score\n",
    "                ],\n",
    "                'model_name': [fedot_model_name for i in range(len(ModelWrapClass.metrics_names()))]\n",
    "            }      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2. Прогнозирование временных рядов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузить датасет если его нет\n",
    "csv_filename = Path(settings.enviroment[\"DATASET_SUBFOLDER\"], \"\", 'Electric_Production.csv')\n",
    "if not Path(csv_filename).exists():\n",
    "    if not Path(settings.enviroment[\"DATASET_SUBFOLDER\"]).exists():\n",
    "        Path.mkdir(Path(settings.enviroment[\"DATASET_SUBFOLDER\"]))\n",
    "    od.download_url(\"https://raw.githubusercontent.com/ejgao/Time-Series-Datasets/refs/heads/master/Electric_Production.csv\", \n",
    "                                Path(settings.enviroment[\"DATASET_SUBFOLDER\"]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим датасет и для ДЗ отберем 5000 строк из датасета\n",
    "original_dataset_df = pd.read_csv(csv_filename)\n",
    "dataset_df = original_dataset_df.copy()\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Преобразование даты в индекс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дату в индекс\n",
    "dataset_df['Date'] = pd.to_datetime(dataset_df['DATE']) # Строки преобразуем в даты\n",
    "dataset_df.set_index('Date', inplace=True)\n",
    "dataset_df.drop('DATE', inplace=True, axis=1)\n",
    "dataset_df.columns = ['EP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим два последних года в тестовую выборку\n",
    "len_test = 24\n",
    "train = dataset_df.head(len(dataset_df)-len_test)\n",
    "test =  dataset_df.tail(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedot.core.data.data import InputData, autodetect_data_type\n",
    "from fedot.core.data.data_split import train_test_data_setup\n",
    "from fedot.api.main import Fedot\n",
    "from fedot.core.repository.tasks import Task, TaskTypesEnum, TsForecastingParams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = dataset_df['EP']\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры прогнозирования\n",
    "forecast_length = 24  # Сколько шагов вперед прогнозируем\n",
    "task = Task(TaskTypesEnum.ts_forecasting,\n",
    "            TsForecastingParams(forecast_length=forecast_length))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Создаем объект InputData для FEDOT\n",
    "input_data = InputData.from_numpy(\n",
    "    features_array=series.values,\n",
    "    target_array=series.values,  # Для временных рядов features и target совпадают\n",
    "    task=task,\n",
    "    idx=series.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем объект InputData для FEDOT\n",
    "input_data = InputData(\n",
    "    idx=series.index,\n",
    "    task=task,\n",
    "    features=series.values,\n",
    "    target=series.values,  # Для временных рядов features и target совпадают\n",
    "    data_type=autodetect_data_type(task)\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на train/test\n",
    "train_data, test_data = train_test_data_setup(input_data, split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем и настраиваем модель FEDOT\n",
    "model = Fedot(problem='ts_forecasting', \n",
    "              task_params=task.task_params,\n",
    "              preset='best_quality',\n",
    "              n_jobs=-1,\n",
    "              timeout=10,# Время на подбор модели в минутах\n",
    "              seed=settings.enviroment[\"RANDOM_STATE\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "model.fit(features=train_data, target='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прогнозирование\n",
    "forecast = model.predict(test_data)\n",
    "forecast_values = forecast.predict[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация результатов\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.idx, train_data.target, label='Train')\n",
    "plt.plot(test_data.idx, test_data.target, label='Test')\n",
    "plt.plot(test_data.idx[:forecast_length], forecast_values, label='Forecast')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 50\n",
    "\n",
    "# Configure AutoML\n",
    "task_parameters = TsForecastingParams(forecast_length=forecast_horizon)\n",
    "model = Fedot(problem='ts_forecasting', task_params=task_parameters)\n",
    "target_series = dataset_df['EP']\n",
    "target_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obtained_pipeline = model.fit(features=test['EP'], \n",
    "                              target=np.array(target_series))\n",
    "# Use historical value to make forecast\n",
    "forecast = model.predict(dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнительная таблица метрик разных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat = pd.concat([pd.DataFrame(knn_model.metrics()),\n",
    "                     pd.DataFrame(svc_model.metrics()),\n",
    "                     pd.DataFrame(rfc_model.metrics()),\n",
    "                     pd.DataFrame(logreg_model.metrics()),\n",
    "                     pd.DataFrame(dtc_model.metrics()),\n",
    "                     pd.DataFrame(fedot_metrics_as_dict)\n",
    "                     ])\n",
    "columns = ['model_name']\n",
    "columns = columns + ModelClass.metrics_names()\n",
    "df_stat2 = df_stat.pivot_table(columns = 'params',\n",
    "                            index='model_name',\n",
    "                            values='values').reset_index()[columns]\n",
    "df_stat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наибольшая доля правильных предсказаний (accuracy) у моделей SupportVectorMachine и CatBoost(fedot) - 0.71 на тестовой выборке.\n",
    "Лучше всего положительные классы предстказывает SupportVectorMachine - 0.67.\n",
    "Наиболее сбалансированной получается модель Catboost, выбранная с помощью FEDOT - F1=0.75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
